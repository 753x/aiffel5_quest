{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-13T02:00:18.393922Z",
     "start_time": "2023-09-13T02:00:18.129383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Wed Sep 13 11:00:20 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.86.05              Driver Version: 536.99       CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     On  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   32C    P8              10W / 220W |    479MiB /  8192MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'/tmp/rjUq5CpGra'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T02:03:16.698915Z",
     "start_time": "2023-09-13T02:03:16.638990Z"
    }
   },
   "id": "2561122581988068"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 뉴스 요약봇 만들기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85136d4de5a013ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-1. 들어가며\n",
    "\n",
    "### 학습 내용\n",
    "2. 텍스트 요약(Text Summarization)\n",
    " - 텍스트 요약 방법인 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)에 대해서 알아봅니다.\n",
    "3. 인공 신경망으로 텍스트 요약 훈련시키기\n",
    " - seq2seq 모델에 대한 개요와 구조 그리고 요소들에 대해서 알아봅니다.\n",
    "4. 데이터 준비하기\n",
    " - Kaggle에서 제공하는 아마존 리뷰 데이터셋을 다운받고, 데이터를 확인해 봅니다.\n",
    "5.  ~ 7. 데이터 전처리하기\n",
    " - 불용어 제거, 정규화, 정수인코딩 등의 데이터 전처리 과정을 코드로 구현합니다.\n",
    "8. 모델 설계하기\n",
    " - 인코더와 디코더, 어텐셔을 설계하고 코드로 구현합니다.\n",
    "9. 모델 훈련하기\n",
    " - EarlyStopping에 대해서 알아보고, 이를 적용하여 모델을 학습합니다.\n",
    "10. 인퍼런스 모델 구현하기\n",
    " - 정수 인덱스 행렬로 나온 결과값을 실제 데이터로 복원하는 인퍼런스 모델을 코드로 구현합니다.\n",
    "11. 모델 테스트하기\n",
    " - 모델을 통해 얻은 요약문과 실제 요약문을 비교해 봅니다.\n",
    "12. 추출적 요약 해보기\n",
    " - summa 패키지를 사용하여 추출적 요약(Extractive Summarization)을 해봅니다.\n",
    "\n",
    "### 학습 목표\n",
    "\n",
    "Extractive/Abstractive summarization 이해할 수 있습니다.\n",
    "\n",
    "단어장 크기를 줄이는 다양한 text normalization 적용할 수 있습니다.\n",
    "\n",
    "seq2seq의 성능을 Up시키는 Attention Mechanism 적용할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a76e29339507055"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-2. 텍스트 요약(Text Summarization)이란?\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-21-1.png)\n",
    "텍스트 요약(Text Summarization)이란 위 그림과 같이 긴 길이의 문서(Document) 원문을 핵심 주제만으로 구성된 짧은 요약(Summary) 문장들로 변환하는 것을 말합니다. 예를 들어 상대적으로 큰 텍스트인 뉴스 기사로 작은 텍스트인 뉴스 제목을 만들어내는 것이 텍스트 요약의 대표적인 예라고 할 수 있어요.\n",
    "\n",
    "이때 중요한 것은 요약 전후에 정보 손실 발생이 최소화되어야 한다는 점입니다. 이것은 정보를 압축하는 과정과 같습니다. 비록 텍스트의 길이가 크게 줄어들었지만, 요약문은 문서 원문이 담고 있는 정보를 최대한 보존하고 있어야 합니다. 이것은 원문의 길이가 길수록 만만치 않은 어려운 작업이 됩니다. 사람이 이 작업을 수행한다 하더라도 긴 문장을 정확하게 읽고 이해한 후, 그 의미를 손상하지 않는 짧은 다른 표현으로 원문을 번역해 내야 하는 것입니다.\n",
    "\n",
    "그렇게 요약 문장을 만들어 내려면 어떤 방법을 사용하면 좋을까요? 여기서 텍스트 요약은 크게 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)의 두 가지 접근으로 나누어볼 수 있습니다.\n",
    "\n",
    "### 추출적 요약(Extractive Summarization)\n",
    "첫 번째 방식인 추출적 요약은 단어 그대로 원문에서 문장들을 추출해서 요약하는 방식이에요. 가령, 10개의 문장으로 구성된 텍스트가 있다면, 그중 핵심적인 문장 3개를 꺼내와서 3개의 문장으로 구성된 요약문을 만드는 식이죠. 그런데 꺼내온 3개의 문장이 원문에서 중요한 문장일 수는 있어도, 3개의 문장의 연결이 자연스럽지 않을 수는 있거든요. 결과로 나온 문장들 간의 호응이 자연스럽지 않을 수 있다는 것이죠. 딥 러닝보다는 주로 전통적인 머신 러닝 방식에 속하는 텍스트 랭크(TextRank)와 같은 알고리즘을 사용해서 이 방법을 사용한다고 해요.\n",
    "\n",
    "이런 방식을 이미 서비스에 도입해서 활용하고 있는 사례가 있다는 것, 알고 계셨나요? 가장 대표적인 것이 네이버 뉴스 서비스에 있는 요약봇 기능입니다.\n",
    "\n",
    "네이버 뉴스에 접속해서 아무 뉴스 기사나 클릭해 봅시다. 제목 우하단의 요약봇 버튼을 다시 클릭해 보세요. 기사 원문을 단 3줄로 요약한 글을 보실 수 있습니다. 어떤가요? 가끔은 세 문장 간 연결이 조금 매끄럽지 않게 느껴질 때도 있지만 꽤 그럴듯한 요약문으로 보입니다. 위에서 소개한 TextRank 알고리즘을 통해 해당 기사를 가장 잘 대표하는 단어들로 이루어진 핵심문장을 아주 효과적으로 찾아내기 때문입니다. 잘 찾아보면 요약문에 사용된 문장 3개가 원문에 그대로 있다는 것을 알 수 있을 것입니다.\n",
    "\n",
    "### 추상적 요약(Abstractive Summarization)\n",
    "두 번째 방식인 추상적 요약은 추출적 요약보다 좀 더 흥미로운 접근을 사용합니다. 원문으로부터 내용이 요약된 새로운 문장을 생성해내는 것이죠. 여기서 새로운 문장이라는 것은 결과로 나온 문장이 원문에 원래 없던 문장일 수도 있다는 것을 의미합니다. 자연어 처리 분야 중 자연어 생성(Natural Language Generation, NLG)의 영역인 셈이죠. 반면, 추출적 요약은 원문을 구성하는 문장 중 어느 것이 요약문에 들어갈 핵심문장인지를 판별한다는 점에서 문장 분류(Text Classification) 문제로 볼 수 있을 것입니다.\n",
    "\n",
    "자연어 생성하면 혹시 떠오르는 신경망이 있나요? 가장 기본적인 신경망 중 하나인데... 맞아요! RNN으로 이 문제를 풀 수 있겠군요! 그렇다면, RNN으로 추상적 요약 방식을 구현한다고 하면 문제가 전혀 없을까요?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8566f3b741849eff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. RNN은 학습 데이터의 길이가 길어질수록 먼 과거의 정보를 현재에 전달하기 어렵다는 문제가 있습니다. 이 문제를 해결하기 위해 LSTM과 GRU가 등장했고, 이 둘도 부족해서 어텐션(Attention) 메커니즘이 등장했지요. 이 문제의 이름은 무엇인가요?\n",
    "\n",
    "장기 의존성(long term dependencies) 문제\n",
    "\n",
    "장기 의존성 문제는 순환 신경망(RNN)에서 발생하는 문제로, 학습 데이터의 길이가 길어질수록 먼 과거의 정보를 현재에 전달하기 어렵다는 것을 의미합니다. RNN은 시간적인 의존성을 모델링하는 데 강점이 있지만, 그래디언트 소실 또는 그래디언트 폭주와 같은 문제로 인해 장기적인 의존성을 적절히 학습하기 어려울 수 있습니다.\n",
    "\n",
    "장기 의존성 문제를 해결하기 위해 등장한 LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit)은 RNN의 변형 구조로, 기본 RNN보다 더 긴 시간 간격에서의 정보를 보다 효과적으로 전달할 수 있도록 설계되었습니다. LSTM과 GRU는 게이트 메커니즘이라는 구조를 도입하여 그래디언트 흐름을 제어하고 장기적인 의존성을 캡처할 수 있는 기능을 제공합니다.\n",
    "\n",
    "그러나 LSTM과 GRU도 모든 상황에서 완벽한 해결책은 아니며, 특히 입력 시퀀스가 매우 긴 경우에도 여전히 한계가 있습니다. 이에 따라 어텐션 메커니즘이 등장하였습니다. 어텐션은 입력 시퀀스의 다양한 위치에 주목(attention)하여 중요한 정보를 집중(concentrate)시키고, 필요한 정보에 가중치를 부여하여 모델이 장기 의존성을 보다 효과적으로 학습할 수 있게 돕습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3963af6d49ae1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "그저 RNN을 이용해 Language Generation을 한다고 해서 긴 문장을 읽고 나서 요약문을 뚝딱 만들어내긴 어렵겠죠. 어떤 방법을 사용할 지 고민을 할 때, 잘 하는 친구들은 어떻게 하는지 찾아보는 것은 꽤 많은 도움이 돼요. ML 분야의 선구자라고 할 수 있는 기업 '구글(Google)'은 자신들의 서비스에 어떤 방식으로 텍스트 요약을 시도했었을까요? 2016년의 아래 기사에 따르면, 구글은 뉴스 기사 내용으로부터 자동으로 뉴스 제목을 뽑아내는 텍스트 요약 모델을 구현했었다고 합니다. 어떻게 구현했는지, 잠깐 읽어볼까요?\n",
    "\n",
    "\n",
    "구글 인공지능 \"뉴스 제목도 잘 뽑네\"\n",
    "\n",
    "https://zdnet.co.kr/view/?no=20160905114833&from=Mobile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14ef67f1ac099dd2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 구글에서 텍스트 요약을 위해 시도했던 접근법 중에, 텍스트마이닝 분야의 '역문서빈도(IDF)같은' 지표를 활용해 문서 안에서 중요해 보이는 부분을 추출하고 그걸 요약문에 담는 방식을 썼을 때의 문제점은 무엇이었나요?\n",
    "\n",
    "원문에서 발췌하는 방식(Extractive summarization)의 요약 기법은 어색하거나 문법적으로 이상한 결과물을 만드는 문제가 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8d0a3f72b29ba8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 구글은 짧은 문장. 요약문을 생성하는 모델을 딥 러닝을 통해 end-to-end로 설계하도록 했어요. 구글이 메일서비스에 적용한 자동 회신(Smart Reply) 기능을 만든 것과 비슷한 딥러닝 기법이기도 한 인코더와 디코더의 구조로 구성된 이 딥 러닝 아키텍처의 이름은 무엇일까요?\n",
    "\n",
    "구글이 메일서비스에 적용한 자동 회신(Smart Reply) 기능과 유사한 딥러닝 기법으로 구성된 딥 러닝 아키텍처의 이름은 \"Sequence-to-Sequence (Seq2Seq) 모델\"입니다. Seq2Seq 모델은 인코더와 디코더라는 두 개의 주요 구성 요소로 이루어져 있습니다.\n",
    "\n",
    "인코더는 입력 시퀀스(예: 원본 문장)를 고정된 크기의 잠재 벡터(latent vector)로 인코딩하는 역할을 합니다. 이 잠재 벡터는 입력 시퀀스의 의미와 정보를 담고 있습니다.\n",
    "\n",
    "디코더는 인코더에서 얻은 잠재 벡터를 기반으로 출력 시퀀스(예: 요약문)를 생성하는 역할을 합니다. 디코더는 시작 토큰을 입력으로 받아서 한 번에 하나의 토큰을 생성하며, 이전에 생성된 토큰들과 현재 상태를 사용하여 다음 토큰을 예측합니다. 이런 식으로 디코더가 한 단어(또는 문자) 씩 출력하여 최종적으로 요약문을 완성합니다.\n",
    "\n",
    "Seq2Seq 모델은 번역, 대화 생성, 요약 등 다양한 자연어 처리 작업에서 활용되며, 구글의 Smart Reply와 같이 짧은 문장에 대한 요약/응답 생성에도 사용됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d5c812bed00774"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-3. 인공 신경망으로 텍스트 요약 훈련시키기\n",
    "\n",
    "우리는 seq2seq 모델을 통해서 Abstractive summarization 방식의 텍스트 요약기를 만들어볼 거예요. seq2seq은 두 개의 RNN 아키텍처를 사용하여 입력 시퀀스로부터 출력 시퀀스를 생성해 내는 자연어 생성 모델입니다. 주로 뉴럴 기계번역에 사용되는 이 모델이 텍스트 요약에도 사용될 수 있을지 갸우뚱하실 수도 있겠지만, 원문을 요약문으로 번역한다고 생각한다면 전혀 무리가 없겠죠?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce61ac8c6477bd1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "seq2seq 개요\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/E-21-2.max-800x600.png)\n",
    "\n",
    "https://medium.com/dl-for-product-and-service/abstractive-text-summary-with-reinforcement-learning-ab2458ab29d5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c6c1aedb9c12b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "원문을 첫 번째 RNN인 인코더로 입력하면, 인코더는 이를 하나의 고정된 벡터로 변환해요. 이 벡터를 문맥 정보를 가지고 있는 벡터라고 하여 컨텍스트 벡터(context vector)라고 합니다. 두 번째 RNN인 디코더는 이 컨텍스트 벡터를 전달받아 한 단어씩 생성해내서 요약 문장을 완성하는 거죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99b44bcc50c17d6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  LSTM과 컨텍스트 벡터\n",
    "\n",
    "우리는 seq2seq를 구현할 때, 인코더/디코더로 바닐라 RNN이 아니라 LSTM을 사용할 거예요.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/E-21-3.max-800x600.png)\n",
    "\n",
    "[RNN과 LSTM]\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4a1d582f89e6133"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LSTM이 바닐라 RNN과 다른 점은 다음 time step의 셀에 hidden state뿐만 아니라, cell state도 함께 전달한다는 점이에요. 다시 말해, 인코더가 디코더에 전달하는 컨텍스트 벡터 또한 hidden state h와 cell state c 두 개의 값 모두 존재해야 한다는 뜻이죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "110db78f1cae2649"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 시작 토큰과 종료 토큰\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-21-4.png)\n",
    "\n",
    "[시작 토큰 SOS와 종료 토큰 EOS는 각각 start of a sequence와 end of a sequence를 나타낸다]\n",
    "https://arxiv.org/pdf/1812.02303.pdf\n",
    "\n",
    "seq2seq 구조에서 디코더는 시작 토큰 SOS가 입력되면, 각 시점마다 단어를 생성하고 이 과정을 종료 토큰 EOS를 예측하는 순간까지 멈추지 않아요. 다시 말해 훈련 데이터의 예측 대상 시퀀스의 앞, 뒤에는 시작 토큰과 종료 토큰을 넣어주는 전처리를 통해 어디서 멈춰야 하는지 알려줄 필요가 있겠죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9057e8d089c80209"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d14a5382d0ecb442"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "938d518e5c6d2478"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "65329f3d21ca99aa"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fa9a75b09c268de7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a316e0b3f398affc"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff65bea870492d83"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1228d4d9d4f34702"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6307394859ac9b39"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e756d9b19aabf2b5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c771600a20200da0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3582d1e8ef7966f5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ca48cf279223b18d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c44b8cbbd300c6e1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61a82160e128cf0f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3bbed9136a6f2adc"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8056753e470c7c61"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e3c49feae6c5e42b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bb941b87d4339982"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a8ba6b3c94b3bb"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11e027446f16251c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c9ca33932e973c38"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9b7acecaf11d562f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a416d3e53e1b125d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3683ee6fea8b2b21"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "24c040fbbd51bf01"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3b81d801a4205d9b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5913adaf9a73ab1d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ac3eb235cb9e194d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e69b8540280e1e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1233ef8a07defc8c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "27c27ac3ed8c168f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d3dee094a9d09a75"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b5410138cdebead5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c18b4efcce9a6d7a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d81d3d5c1ba9f978"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c9dd47dc183c4319"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "34162fd46de4367f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ab2b332ccda934e1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b63973c679bf5116"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1647cbbedfe5bf9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af1853dac31070fe"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "12216a057fe1870"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f888690f2f0a3962"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eccbdf02bc6c66a9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef3e9ccb6355c54"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "470556b81b83066d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "693b62e58219eb71"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "27b1674ebde638a0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59dfcd9a7d50b8b4"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f82833ba28499e51"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "861b451f0a7f2300"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46a5004df58b56ed"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8db7332dc43e0ae"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36c6efb3a274612b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6f115d1f22231ff4"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aa316835dc0eaa1b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f832f587eb063577"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f2baa9144c4c4118"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eaaf43dad3171b3a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "400f66991f99624"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "db76cea45ff2487f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fe25d84ead6b3394"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e962c0dec34d9770"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8e3ec274f519bb12"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "54bb9c7685a309f7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a084f8e5f07a3787"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a88d91aa11bb2c9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5abadd99ddbeedb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
