{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 딥러닝으로 시작하는 컴퓨터 비전\n",
    "### 4. CNN 하나씩 이해하기 (2) 3-Channel Convolution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4-1. 들어가며"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/01.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/02.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 학습 내용\n",
    "\n",
    "Channel이 3개일 때, 1-Layer의 Convolution 연산\n",
    "\n",
    " - Channel이 3개일 때, Convolution 연산 방식을 이해하고 Channel이 1개 일 때와 다른 부분을 이해하고 feature map의 크기를 직접 구해봅시다.\n",
    "\n",
    "Hyper-Parameter에 대한 고민 (Kernel size, Channel size, Stride)\n",
    "\n",
    " - Convolution 연산을 할 때, Hyper-Parameter(kernel size, channel size, stride)에 대한 고민을 각 개념에 대입해 생각해 봅시다.\n",
    "\n",
    "1x1 Convolution\n",
    "\n",
    " - 1x1 Convolution의 특징과 사용했을 때의 장점에 대해서 알아봅시다.\n",
    "\n",
    "Transposed Convolution\n",
    "\n",
    " - Transposed Convolution에 대해서 알아보고 직접 손으로 연산을 해보며, Convolution 연산과의 차이점을 알아봅시다.\n",
    "\n",
    "#### 학습 목표\n",
    "\n",
    "3 Channel 일 때 Convolution 연산 방식을 설명할 수 있습니다.\n",
    "\n",
    "Convolution 연산의 결과로 나온 feature map의 차원을 계산할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/03.png)\n",
    "\n",
    "7*7*3 의 이미지가 있다.\n",
    "\n",
    "채널 하나당 커널 하나가 붙게 된다.\n",
    "\n",
    "커널 3개가 filter1개로 구성된다. 커널은 채널 1개당 1개로 할당 된다.\n",
    "\n",
    "필터는 커널의 상위 개념\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/05.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "최종 feature map\n",
    "![](./img04/06.png)\n",
    "![](./img04/07.png)\n",
    "\n",
    "(5*5)*3 개의 칸에 같은 값의 bias가 더해진다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/08.png)\n",
    "![](./img04/09.png)\n",
    "\n",
    "이미지 데이터(인풋)의 채널수와 피쳐맵 데이터의 채널수는 같지 않다\n",
    "\n",
    "피쳐맵의 채널수는 필터의 갯수와 같다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/10.png)\n",
    "\n",
    "하나의 레이어에서 두개의 필터를 가지고 연산을 끝냈더니 피쳐맵은 두개가 나옴\n",
    "\n",
    "하나의 컨볼루션 레이어를 더 쌓았다면 새롭개 만들 피쳐맵이 다음 레이어의 인풋이다.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 7 x 7 x 3의 input에 3x3의 kernel, stride 1인 Convolution 연산을 하면 output의 크기는 어떻게 되나요? feature map의 크기는 어떻게 되나요? (연산과정을 찬찬히 생각하면서 작성해 보세요. ☺️)\n",
    "\n",
    "kernel은 input의 channel 수만큼 존재하고, 각 channel 수준에서 Convolution 2D 연산을 계속하면 channel 수만큼의 output이 생깁니다. 따라서 output은 5 x 5 x 3이 나옵니다.\n",
    "\n",
    "filter 1개로 feature map 1개를 만들 수 있습니다. 3개의 output의 동일한 위치의 숫자를 더하고 거기에 1번 filter의 bias를 더하여 1번 filter의 5 x 5 feature map을 만들 수 있습니다. 즉 “(5 x 5) x 3”개의 칸에 같은 값(bias)이 더해져 feature map을 만듭니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. filter마다 위의 연산과정을 반복하게 됩니다. filter은 어떤 역할을 하고 filter가 많으면 어떻게 되는지 설명해 보세요.\n",
    "\n",
    "filter는 feature extractor입니다. 이미지 데이터가 가지고 있는 특징, pattern을 추출해 주는 역할을 합니다. filter가 많을수록 여러 개의 feature map이 생기며 복잡하고 다양한 pattern을 찾을 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. input의 channel 수, feature map의 channel 수, filter의 개수의 관계에 대해서 설명해 보세요.\n",
    "input의 channel 수와 feature map의 channel 수는 다르지만, filter의 개수와 feature map의 channel 수는 같습니다. (feature map은 activation map이라고도 많이 씁니다.)\n",
    "\n",
    "filter의 개수는 feature map의 channel 수를 결정합니다. filter의 개수가 1개이면 feature map의 channel 수도 1개입니다. filter의 개수가 2개이면 feature map의 channel 수도 2개입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4-3. Hyper-Parameter에 대한 고민 (Kernel size, Channel size, Stride)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convolution 연산을 할 때, Hyper-Parameter에 대한 고민을 해야 합니다. 이번 스텝에서는 kernel size, channel size, stride에 대해 고민해 봅시다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Kernel Size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kernel size가 커질수록 연산을 통해 찾아야 하는 파라미터의 수가 증가하게 됩니다.\n",
    "\n",
    "Kernel size가 작아질수록 데이터에 존재하는 global feature보다 local feature에 집중하게 됩니다.\n",
    "\n",
    "쉽게 표현하자면 큼직한 특징보다는 지엽적인 특징에 집중해서 패턴을 찾게 됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Channel size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter의 channel size가 커질수록 convolution 연산을 통해서 더 다양한 패턴을 찾을 수 있습니다.\n",
    "\n",
    "그러나 channel의 사이즈가 커짐에 따라서 연산으로 찾아야 하는 파라미터의 숫자가 증가하게 됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Stride"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stride 값이 커지면 데이터를 빠르게 훑고 지나가는 연산을 하게 됩니다.\n",
    "\n",
    "따라서 지역적인 특징을 꼼꼼하게 살펴보아야 할 경우에는 stride값을 크게 하는 것이 좋지 않습니다.\n",
    "\n",
    "안타깝게도 이러한 hyperparameter의 값을 어떻게 정하는 것이 최적이라는 규칙을 찾는 것은 매우 어려운 일입니다.\n",
    "\n",
    "따라서 연구자는 시행착오를 스스로의 실습으로 해거나 AutoML과 같은 방법으로 hyperparameter를 스스로 tuning해야 합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "** AutoML은 머신러닝과 딥러닝을 적용할 때마다 반복적인 과정으로 발생하는 비효율적인 작업(하이퍼 파라미터 실험, 문제 적합한 architecture를 찾는 과정 등)을 최대한 자동화하여 생산성과 효율을 높이기 위하여 등장한 것으로, 현재 다양한 툴들이 개발되어 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "일반적으로 해당 task에서 가장 좋은 성능을 보여주는 모델의 hyperparameter를 그대로 따라하는 경우가 많습니다.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Convolution 연산을 할 때와 모델을 학습할 때에는 다양한 hyperparameter의 값을 정해야 합니다. hyperparameter와 많이 혼용해서 사용되는 개념인 매개변수 parameter에 대해서 알아봅시다. 각각의 개념을 찾아보고 두 개념의 차이점에 대해서 설명해 보세요.\n",
    "\n",
    "파라미터와 하이퍼파라미터 모두 매개변수(parameter)이지만, 두 개념은 차이점이 있습니다.\n",
    "\n",
    "• 파라미터 (Parameter) : 파라미터는 모델 내부에서 학습되는 변수입니다.\n",
    "예) weight coefficient(가중치 계수), bias(편향치)\n",
    "• 하이퍼파라미터 (Hyperparameter) : 하이퍼 파라미터는 사용자가 직접 세팅해 주는 값을 말합니다.\n",
    "예) learning rate, batch size 등"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4-4. 1x1 Convolution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convolution 학습을 수행하는 layer를 사용해서 원하는 모델을 구성할 때는 Filter의 Channel 수를 직접 결정해야 합니다. 이전에 언급한 대로, 일반적으로는 좋은 성능을 보이는 논문에서의 구조를 그대로 따라하지만, 때로는 연구자가 직접 결정해주어야 합니다.\n",
    "\n",
    "channel size가 지나치게 크면 학습을 통해 찾아야 하는 파라미터 숫자가 증가하기 때문에 많은 연산 비용을 들여야만 합니다. 하지만 1x1 Convolution을 사용하면 연산량을 매우 쉽게 줄일 수 있습니다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/NoDeu4-4.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "때로는 feature map의 가로 세로 사이즈는 변화시키지 않고 channel size만 변형하고 싶을 때가 있습니다. 물론 padding을 통하여 가로 세로 사이즈에 대한 변경없이 channel size만 변경할 수 있지만 파라미터 숫자 증가에 따른 연산량 증가의 문제를 피할 수 없습니다. 이럴 때 1x1 convolution은 연산량의 문제를 회피하면서도 channel size를 원하는 대로 변경하는 데에 도움을 줍니다.\n",
    "\n",
    "Q. 1x1 Convolution을 사용하면 연산량을 매우 쉽게 줄일 수 있습니다. 계산량이 실제로 줄어드는지 예시 2개를 풀어보고, 두 개의 값을 비교하여 생각해 보세요.\n",
    "\n",
    "[예시 1] 28x28x192 image 데이터에 (5x5 filter, 32 channel) convolution 연산을 적용한다고 해 봅시다. 이때, feature map의 크기와 파라미터 수에 대해서 생각해 보세요.\n",
    "[예시 2] 28x28x192 image 데이터에 (1x1 filter, 16 channel) convolution 연산을 사용하여 channel을 줄인 뒤, 이어서 (5x5 filter, 32 channel) convolution 연산을 적용 한다고 해 봅시다. 이때, feature map의 크기와 파라미터 수에 대해서 생각해 보세요.\n",
    "\n",
    "예시 1\n",
    "특징 맵의 크기 계산: 스트라이드 1, 패딩 없음인 경우 출력 특징 맵의 크기는 다음과 같이 계산됩니다:\n",
    "(입력 이미지 높이 - 필터 높이) / 스트라이드 + 1 = (28 - 5) / 1 + 1 = 23 / 1 + 1 = 23 + 1 = 24\n",
    "(입력 이미지 너비 - 필터 너비) / 스트라이드 + 1 = (28 - 5) / 1 + 1 = 23 / 1 + 1 = 23 + 1 = 24 따라서 특징 맵의 크기는 24x24이고, 채널 수는 32입니다. 그러므로 24x24x32의 특징 맵이 생성됩니다.\n",
    "파라미터 수 계산: 파라미터는 각각의 필터에 대해 계산되어야 하며, 다음과 같은 방식으로 계산됩니다:\n",
    "가중치 파라미터: (필터 높이 x 필터 너비 x 입력 이미지 채널 수) x 출력 채널 수 = (5 x 5 x 192) x 32 = 153,600\n",
    "편향 파라미터: 출력 채널 수 = 32 따라서 가중치 파라미터와 편향 파라미터의 합계인 총 파라미터 수는 153,600 + 32 = 153,632개입니다\n",
    "\n",
    "파라미터 수(연산량)는 28 x 28 x 32 x 5 x 5 x 192 = 120,422,400 약 1.2억 번의 연산이 필요합니다.\n",
    "\n",
    "예시 2의 feature map의 크기도 24x24x32가 나옵니다. 먼저, 1x1 filter를 사용해서 크기를 줄일 때 사용되는 파라미터 수(연산량)는 28 x 28 x 16 x 1 x 1 x 192 = 2,408,448 약 240만 번의 연산이 필요합니다. 다시 5x5 filter를 사용하면 28 x 28 x 32 x 5 x 5 x 16 = 10,035,200 약 1000만 번의 연산이 필요합니다. 그럼 총 약 1240만 번의 연산이 필요합니다.\n",
    "\n",
    "예시 1과 예시 2의 파라미터 수(연산량)는 1.2억 번(12000만 번) 과 1240만 번의 연산으로 10배 가까이 차이 나는 것을 확인할 수 있습니다. 실제로 1x1 convolution은 연산량의 문제를 회피하면서도 channel size를 원하는 대로 변경하는 데에 도움을 줍니다. 직접 수치로 비교하니 더 이해가 잘 되지 않나요? 🤔😉"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4-5. Transposed Convolution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/11.png)\n",
    "\n",
    "인풋이미지를 컨볼루션 하면 채널수는 더 많아지고 가로세로는 줄어든다.\n",
    "\n",
    "Latent Space Representation은 보이지 않은 패턴을 찾아낸 결과물을 의미한다\n",
    "\n",
    "왼쪽은 일종의 압축과정, 오른쪽은 압축을 해제하는 과정이다. Encoder와 Decoder의 과정이라고 볼 수 있다.\n",
    "\n",
    "압축을 해제하는 과정을 Transposed Convolution이라고 한다. 동의어로 Deconvolution 혹은 Upscaling이라고도 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/12.png)\n",
    "\n",
    "Segmentation : input 이미지가 들어가면 output은 pixel 별 class를 나타내는 이미지가 나온다.\n",
    "\n",
    "input으로 256*256*3 이미지가 들어가면 output은 256*256*class 수 만큼의 이미지가 나온다.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/13.png)\n",
    "\n",
    "Output : 6*6\n",
    "\n",
    "kernal : 3*3\n",
    "\n",
    "input : 4*4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/14.png)\n",
    "\n",
    "stride는 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Transposed Convolution을 사용하는 이유와 특징에 대해서 설명해 보세요.\n",
    "\n",
    "Transposed Convolution은 Auto-Encoder 구조에서 입력 정보가 압축된 compressed representation을 다시 원래 입력 사이즈로 반환하기 위해 사용합니다. 정보를 축약하는 down-sampling이라는 표현과 반대로 up-sampling 한다고 말하기도 합니다. Low-resolution의 이미지를 high-resolution으로 바꾸는 역할도 할 수 있고, Pixel 별로 할당된 정답 값을 맞추는 task인 semantic segmentation에서도 활용할 수 있습니다.\n",
    "\n",
    "GPT 답변\n",
    "Transposed Convolution(또는 Deconvolution, Fractionally-strided Convolution)은 컨볼루션 레이어와 반대 방향으로 작동하는 연산입니다. Transposed Convolution이 주로 사용되는 이유는 고해상도 이미지를 복원하거나, 이미지 세분화와 같은 응용 사례에서 입력 정보를 원래 크기로 재구성하는 경우입니다. 일반적으로 활성화 맵(activation map)을 입력 이미지와 동일한 해상도와 크기로 확장하는 과정에서 사용됩니다.\n",
    "\n",
    "Transposed Convolution의 주요 특징은 다음과 같습니다:\n",
    "\n",
    "1. 업샘플링: Transposed Convolution의 주요 목적은 업샘플링입니다. 즉, 입력 이미지를 더 큰 해상도로 복원하기 위해 사용됩니다. 이는 이미지 세분화와 같은 작업에서 중요한 역할을 합니다.\n",
    "\n",
    "2. 재구성: Transposed Convolution은 이미지나 출력 정보를 원래 형태로 재구성해야 하는 Autoencoder와 같은 모델에서 유용하게 사용됩니다. 이 때, 이미지의 고해상도 버전을 생성하기 위해 사용되며, 업샘플링 뿐만 아니라 다양한 정보를 재구성하는 역할을 수행합니다.\n",
    "\n",
    "3. 경계 아티팩트: Transposed Convolution을 사용할 때 경계 아티팩트(border artifacts)에 유의해야 합니다. 이는 업샘플링 과정에서 발생할 수 있는 불규칙한 밝기 변경과 같은 현상입니다. 이를 해결하기 위해 학습 데이터를 증가시키거나 다양한 네트워크 구조를 사용할 수 있습니다.\n",
    "\n",
    "4. 학습 가능: Transposed Convolution은 일반 컨볼루션과 마찬가지로 학습 가능한 가중치와 편향 값을 가집니다. 따라서 이러한 값을 최적화하여 더 높은 성능을 얻을 수 있습니다.\n",
    "\n",
    "Transposed Convolution은 업샘플링 및 재구성 과정에서 중요한 역할을 하는 연산이며, 다양한 딥러닝 애플리케이션에서 사용되는 기술입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 아래 조건을 보고 Transposed Convolution 연산이 어떻게 진행되는지 Convolution 연산과 어떤 차이점이 있는지 직접 손으로 그려서 확인해 보세요.\n",
    "\n",
    "- Input: 4 x 4\n",
    "- kernel: 3 x 3\n",
    "- Output: 6 x 6\n",
    "- stride: 1\n",
    "\n",
    "Transposed Convolution(또는 Deconvolution이나 Fractionally-strided Convolution이라고도 함)은 컨볼루션 레이어와 반대 방향으로 작동하는 연산입니다. Convolution 연산은 이미지를 축소(다운샘플링)하는 반면, Transposed Convolution은 이미지를 확장(업샘플링)합니다.\n",
    "\n",
    "주어진 조건을 기준으로 Transposed Convolution 연산을 설명하고, Convolution 연산과의 차이점을 확인해 보겠습니다.\n",
    "\n",
    "1. Input: 입력 이미지의 크기가 4 x 4입니다.\n",
    "2. Kernel: 컨볼루션 필터의 크기가 3 x 3입니다.\n",
    "3. Output: 출력 이미지의 크기가 6 x 6입니다.\n",
    "4. Stride: 스트라이드(간격)가 1입니다.\n",
    "\n",
    "Transposed Convolution의 과정은 다음과 같습니다:\n",
    "\n",
    "1. 먼저 입력 이미지에 스트라이드-1에 맞는 Zero-padding을 적용합니다. 이때 Applied Padding은 Kernel Size - Stride로 계산되므로 3 - 1 = 2의 패딩이 적용됩니다. 결과적으로 7 x 7 크기의 이미지를 얻습니다.\n",
    "\n",
    "2. 다음으로, 3 x 3 커널을 사용하여 스트라이드 1에 맞는 일반적인 컨볼루션 연산을 수행합니다. 결과적으로 6 x 6 크기의 출력 이미지를 생성합니다.\n",
    "\n",
    "Convolution 연산과의 차이점은 다음과 같습니다:\n",
    "\n",
    "1. 입력 이미지 확장: Convolution 연산은 입력 이미지를 축소하는 반면, Transposed Convolution 연산은 입력 이미지를 확장합니다.\n",
    "\n",
    "2. Zero-padding: Transposed Convolution에서는 입력 이미지에 패딩을 적용하고, 일반적인 컨볼루션 연산을 수행하여 이미지를 확장합니다. Convolution 연산에선 필터를 적용한 후 패딩을 적용하는 경우가 많습니다.\n",
    "\n",
    "총론적으로, 주어진 조건에서의 Transposed Convolution 연산은 입력 이미지를 6 x 6 크기로 확장시키는 데 사용되며, 이러한 크기 확장이 일반 컨볼루션 연산과의 주요 차이점입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 7x7x3 image의 데이터에 5x5x3의 필터 5개로 convolution 연산을 했을 때 feature map의 사이즈는 어떻게 되나요? (stride는 1)\n",
    "\n",
    "주어진 조건에서 7x7x3 크기의 이미지 데이터에 5x5x3 크기의 필터 5개를 사용하는 컨볼루션 연산을 수행하여 feature map의 크기를 구해보겠습니다. 스트라이드(stride)는 1로 가정하고 패딩(padding)은 없다고 가정했습니다.\n",
    "\n",
    "특징 맵의 크기 계산은 다음과 같습니다:\n",
    "\n",
    "(입력 이미지 높이 - 필터 높이) / 스트라이드 + 1 = (7 - 5) / 1 + 1 = 2 / 1 + 1 = 2 + 1 = 3\n",
    "(입력 이미지 너비 - 필터 너비) / 스트라이드 + 1 = (7 - 5) / 1 + 1 = 2 / 1 + 1 = 2 + 1 = 3\n",
    "\n",
    "따라서 특징 맵의 크기는 3x3이고 출력 채널 수는 사용된 필터 개수와 같으므로 5입니다. 결국, 3x3x5 크기의 feature map이 생성됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 7x7x3 image의 데이터에 5x5x3의 필터 3개로 convolution 연산을 했을 때 feature map의 사이즈는 어떻게 되나요? (stride는 2)\n",
    "\n",
    "주어진 조건에서 7x7x3 크기의 이미지 데이터에 5x5x3 크기의 필터 3개를 사용하는 컨볼루션 연산을 수행하여 feature map의 크기를 구해보겠습니다. 스트라이드(stride)는 2로 가정하고 패딩(padding)은 없다고 가정했습니다.\n",
    "\n",
    "특징 맵의 크기 계산은 다음과 같습니다:\n",
    "\n",
    "(입력 이미지 높이 - 필터 높이) / 스트라이드 + 1 = (7 - 5) / 2 + 1 = 2 / 2 + 1 = 1 + 1 = 2\n",
    "(입력 이미지 너비 - 필터 너비) / 스트라이드 + 1 = (7 - 5) / 2 + 1 = 2 / 2 + 1 = 1 + 1 = 2\n",
    "\n",
    "따라서 특징 맵의 크기는 2x2이고 출력 채널 수는 사용된 필터 개수와 같으므로 3입니다. 결국, 2x2x3 크기의 feature map이 생성됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 9x9x3 image의 데이터를 3x3xn의 필터 4개로 convolution 연산을 두 번 했을 때, 연산의 결과로 나온 최종 feature map의 사이즈는 어떻게 되나요? (stride는 처음에는 1, 두번째에는 2, n은 입력 데이터의 채널 수와 같습니다.)\n",
    "\n",
    "주어진 조건에 따라 9x9x3 크기의 이미지 데이터에 3x3xn 크기의 필터 4개를 사용하여 컨볼루션 연산을 두 번 수행한 결과의 최종 feature map의 크기를 구해봅시다. 스트라이드(stride)는 첫 번째에 1, 두 번째에 2로 가정하고 패딩(padding)은 없다고 합니다.\n",
    "\n",
    "1. 첫 번째 컨볼루션 연산:\n",
    "- n = 3 (입력 데이터의 채널 수와 같음)\n",
    "- 필터 크기: 3x3x3\n",
    "- 필터 개수: 4\n",
    "- 스트라이드: 1\n",
    "\n",
    "특징 맵의 크기 계산:\n",
    "\n",
    "(입력 이미지 높이 - 필터 높이) / 스트라이드 + 1 = (9 - 3) / 1 + 1 = 6 / 1 + 1 = 6 + 1 = 7\n",
    "(입력 이미지 너비 - 필터 너비) / 스트라이드 + 1 = (9 - 3) / 1 + 1 = 6 / 1 + 1 = 6 + 1 = 7\n",
    "\n",
    "따라서 첫 번째 컨볼루션 연산 후 특징 맵의 크기는 7x7이고 출력 채널 수는 필터 개수와 같은 4개입니다. 결과적인 feature map의 크기는 7x7x4입니다.\n",
    "\n",
    "2. 두 번째 컨볼루션 연산:\n",
    "- n = 4 (이전 연산 결과의 채널 수)\n",
    "- 필터 크기: 3x3x4\n",
    "- 필터 개수: 4\n",
    "- 스트라이드: 2\n",
    "\n",
    "특징 맵의 크기 계산:\n",
    "\n",
    "(입력 이미지 높이 - 필터 높이) / 스트라이드 + 1 = (7 - 3) / 2 + 1 = 4 / 2 + 1 = 2 + 1 = 3\n",
    "(입력 이미지 너비 - 필터 너비) / 스트라이드 + 1 = (7 - 3) / 2 + 1 = 4 / 2 + 1 = 2 + 1 = 3\n",
    "\n",
    "따라서 두 번째 컨볼루션 연산 후 특징 맵의 크기는 3x3이고 출력 채널 수는 필터 개수와 같은 4개입니다. 결과적인 feature map의 크기는 3x3x4입니다.\n",
    "\n",
    "최종적으로, 두 번의 컨볼루션 연산 후 생성된 feature map의 크기는 3x3x4입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img04/15.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 종합 퀴즈\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Convolution 연산은 어떤 연산인지 설명해 보세요.\n",
    "\n",
    "Convolution 연산은 이미지 내의 패턴을 자동으로 추출하는 Filter(그 안의 Kernel)를 이용해서 숨겨진 패턴을 찾는 연산입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Filter와 Feature map의 관계에 대해서 배운 내용을 설명해 보세요.\n",
    "\n",
    "Filter의 개수에 따라서 Feature map의 개수가 결정됩니다. 또한, Filter 여러 개를 사용하면 다양한 Feature map을 만들어낼 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
