{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 딥러닝으로 시작하는 컴퓨터 비전\n",
    "### 8. Object Detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8-1. 들어가며"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/01.png)\n",
    "![](./img08/02.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 학습 내용\n",
    "Image Classification vs. Localization vs. Object Detection\n",
    "\n",
    " - Computer Vision 내의 Task들의 개념을 복습해 보고 Object Detection과 Localization (+ Classification)을 비교해 보며 개념을 정리해 봅시다.\n",
    "\n",
    "Object Detection 모델의 발전 과정\n",
    "\n",
    " - Object detection 모델들을 Two-Stage Detector와 One-Stage Detector로 나눠서 이해하고 어떤 차이점이 있는지 생각해 봅시다.\n",
    "\n",
    "R-CNN 모델을 통해 Object Detection 이해하기\n",
    "\n",
    " - R-CNN 모델의 전체적인 구조를 보며 학습 과정을 이해하고 각 단계별로 관련 개념과 학습과정을 자세히 알아봅시다.\n",
    "\n",
    "#### 학습 목표\n",
    "\n",
    "Object detection이 컴퓨터 비전의 다른 task 들과 어떤 차이점을 갖는지 설명할 수 있습니다.\n",
    "\n",
    "Object detection 모델의 서로 다른 두 가지 흐름이 어떤 차이점을 갖는지 설명할 수 있습니다.\n",
    "\n",
    "R-CNN의 예를 통해서 object detection 모델이 어떤 형태를 갖는지 설명할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/03.png)\n",
    "\n",
    "이미지 안에 하나의 객체가 있는 경우와 여러 객체가 있는 경우\n",
    "\n",
    "Classification : 이미지 안에 객체가 있는지 없는지를 판단\n",
    "\n",
    "Localization : 이미지 안에 객체가 있는 경우 객체의 위치를 찾아내는 것(feat : bounding box)\n",
    "\n",
    "Object Detection : 이미지 안에 객체가 있는 경우 객체의 위치를 찾아내고 객체가 무엇인지 분류하는 것\n",
    "\n",
    "Object Detection은 Classification과 Localization을 합친 것이라고 볼 수 있다.\n",
    "\n",
    "semantic segmentation : 객체의 위치를 찾아내는 것 + 객체가 무엇인지 분류하는 것 + 객체의 픽셀까지 분류\n",
    "\n",
    "instance segmentation : 객체의 위치를 찾아내고 객체가 무엇인지 분류하는 것 + 픽셀 레벨 분할의 일부인 각 객체의 픽셀까지 분류하는 것"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/04.png)\n",
    "\n",
    "가장 적절하게 지정하다 의미 : 고양이 이미지 안 오브젝트의 일부만 포함하는 바운딩박스가 있다면 그것은 적절한 바운딩 박스가 아니다.\n",
    "\n",
    "만약 바운딩 박스가 지나치게 커서 객체를 포함은 하지만 객체랑 관련없는 부분까지 포함하고 있다면 그것은 적절한 바운딩 박스가 아니다.\n",
    "\n",
    "object detection의 난이도가 훨씬 높다. 하나의 이미지 안에 있는 여러 대상의 이미지 위치와 분류를 해야 하기 때문이다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/05.png)\n",
    "\n",
    "single object detection : 이미지 안에 하나의 객체가 있는 경우\n",
    "\n",
    " - CNN을 이용하여 feature extraction 진행 후 multi object detection에 진행하면 feature는 잘 찾지만 객체의 위치를 잘 찾지 못한다.\n",
    "\n",
    "multi object detection : 이미지 안에 여러 객체가 있는 경우"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Computer Vision에는 다양한 Task들이 있습니다. 그 Task 안에서도 이미지 안에 하나의 객체가 있는 경우(Single Object)와 이미지 안에 여러 개의 객체가 있는 경우(Multiple Objects)로 크게 2가지로 분류할 수 있습니다. 이 2가지 경우에 해당하는 Task는 어떤 게 있었고 어떤 특징이 있는지 설명해 보세요.\n",
    "\n",
    "1️⃣ Single Object\n",
    "• Image Classification: 단 하나의 대상의 true label이 무엇인지 분류합니다.\n",
    "• Localization: 단 하나의 대상의 위치를 가장 적절하게 지정하는 bounding box(좌표)를 찾습니다.\n",
    "\n",
    "2️⃣ Multiple Objects\n",
    "• Object Detection: 여러 개의 bounding box를 찾아 여러 대상의 위치를 가장 적절하게 지정하는 동시에 각 bounding box 내의 대상을 판별합니다.\n",
    "• Segmentation: 픽셀 단위별로 detection을 수행합니다. (특정 픽셀이 속한 대상 판별) Segmentation 종류에는 Semantic Segmentation와 Instance Segmentation가 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Localization (+ Classification)과 Object Detection의 공통점과 차이점에 대해서 설명해 보세요.\n",
    "\n",
    "Localization과 Detection 모두 대상의 위치를 bounding box로 지정하고, 해당 bounding box 내의 대상이 무엇인지를 판별합니다. 두 task의 차이점으로는 Localization과 비교하면, Object Detection은 하나의 이미지 내의 여러 대상의 위치를 찾고 분류해야 하기 때문에 Localization에 비해 난이도가 높다는 점이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. AlexNet, VGG 등 일반적인 CNN 모델만 사용해서 Object Detection task를 해결할 수 있을까요?\n",
    "\n",
    "일반적인 CNN 모델만 사용해서 Object Detection task를 해결할 수 없습니다. 일반적인 CNN 모델은 이미지의 feature를 추출하는 것에는 탁월하지만, 이미지 내의 여러 대상의 위치를 찾는 것에는 적합하지 않기 때문입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8-3. Object Detection 모델의 발전 과정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/06.png)\n",
    "\n",
    "딥러닝 기반의 object detection도 2012년 이후 쏟아져 나옴\n",
    "\n",
    "One Stage Detector : Two Stage Detector과정을 한번에 함. YOLO, SSD\n",
    "\n",
    "Two Stage Detector : Region Proposal(1st) -> Classification / Bounding Box(2nd). R-CNN, Fast R-CNN, Faster R-CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/07.png)\n",
    "\n",
    "Faster R-CNN : RPN(Region Proposal Network)을 통해 Region Proposal을 뽑아내고, 이후 Fast R-CNN을 통해 Classification과 Bounding Box Regression을 수행합니다.\n",
    "\n",
    "Proposal : 이미지에서 객체가 있을 만한 후보 영역을 찾는 것 = Region Proposal\n",
    "\n",
    "느리지만 정확"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/08.png)\n",
    "\n",
    "ROI를 뽑는 대신에 이미지 전체를 대상으로 Classification과 Bounding Box Regression을 수행합니다.\n",
    "\n",
    "특정 Cell 중심에 오브젝트가 있다고 판단될때 그 Cell에 대해 Classification과 Bounding Box Regression을 수행합니다.\n",
    "\n",
    "빠르지만 상대적으로 정확도가 떨어짐\n",
    "\n",
    "자율주행과 관련 task를 수행할때, 영상관련 task를 수행할때 One Stage Detector를 많이 사용한다.(real time process 수행시)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Object Detection task 방법에는 1-stage detector과 2-stage detector가 있습니다. 그 중에서 Two-Stage Detector의 특징과 장점에 대해서 설명해 보세요.\n",
    "\n",
    "Two-Stage Detector는 Region Proposal을 먼저 진행하면서 이미지 내에 대상이 있을 법한 영역인 RoI(Region of Interest)를 찾아냅니다. 그 찾아낸 RoI 안에 있는 이미지를 classification 합니다.\n",
    "\n",
    "Two-Stage Detector는 두 단계로 나누어져서 느리지만, 정확도가 비교적 높다는 장점이 존재합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Object Detection 모델 중, Two-Stage Detector인 모델을 찾아보고 작성해 보세요.\n",
    "\n",
    "대표적으로 R-CNN 계열의 모델들이 있습니다. (R-CNN, Fast R-CNN 등) 그 외에도 SPPNet, Pyramid Networks 등이 있습니다.\n",
    "Two-Stage Detector인 모델로는 R-CNN, Fast R-CNN, Faster R-CNN 등이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 이번에는 One-Stage Detector의 특징과 장점에 대해서 설명해 보세요.\n",
    "\n",
    "One-Stage Detector는 Region Proposal과 Classification을 동시에 수행합니다. RoI를 찾아내는 대신, 이미지 전체를 대상으로 Classification을 수행합니다. YOLO v1의 경우에는 전체 이미지를 특정 크기의 grid로 분할한 후, cell의 중심에 object가 있다고 판단되는 특정 cell에 대하여 classification을 수행합니다.\n",
    "\n",
    "속도는 Two-Stage Detector보다 빠르지만 정확도는 상대적으로 떨어질 수 있습니다. (현재는 정확도가 많이 개선되었습니다.) 자율주행 자동차, 영상 등 real-time processing을 요구하는 태스크에는 One-Stage Detector가 자주 활용됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Object Detection 모델 중, One-Stage Detector인 모델을 찾아보고 작성해 보세요.\n",
    "\n",
    "대표적으로 YOLO 계열의 모델들이 있습니다. (YOLO v1, YOLO v2, YOLO v3, YOLO v4 등) 그 외에도 SSD, RetinaNet 등이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8-4. R-CNN 모델을 통해 Object Detection 이해하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/09.png)\n",
    "\n",
    "첫번째 Step : ROI를 찾는다.\n",
    "\n",
    "두번째 Step : warped resion(모양을 변경한다)\n",
    "\n",
    "세번째 Step : CNN을 통해 feature extraction을 한다.\n",
    "\n",
    "네번째 Step : classification을 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/10.png)\n",
    "\n",
    "ROI 후보를 2000개 추출하여 동일한 사이즈(227x227)로 변환 후 CNN (Pre-trained model)을 통해 feature extraction을 한다.\n",
    "\n",
    "4096차원의 feature vector를 추출 후 SVM(Support vector machine)을 통해 classification을 한다.\n",
    "\n",
    "SVM을 통해 나온 결과를 바탕으로 bounding box regression을 한다.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/11.png)\n",
    "\n",
    "Sliding window 학습 후 Selective Search를 학습\n",
    "\n",
    "Selective Search : 주변 필셀 간 유사도를 계산\n",
    "\n",
    "유사도 계산 후 Segmentation을 수행 (초기는 아주 세밀한 영역까지 Segmentation을 수행)\n",
    "\n",
    "유사도가 비슷한 segmention으르 반복적으로 Grouping을 수행\n",
    "\n",
    "input --> region proposal --> feature extraction(2000개) --> CNN --> SVM, bounding box regression\n",
    "\n",
    "2000개의 특징을 뽑아내는 것까지를 1번의 task로, 뽑아낸 특징을 바탕으로 분류 후 bounding box regression을 수행하는 것을 2번의 task로 볼 수 있다.\n",
    "\n",
    "그래서 RCNN은 End-to-End로 학습이 불가능하다. 1번의 task를 수행한 후 2번의 task를 수행해야 하기 때문이다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/12.png)\n",
    "\n",
    "Classification 진행 후 Bounding Box Regression을 수행\n",
    "\n",
    "IoU(Intersection over Union) : 두 영역의 교집합 / 두 영역의 합집합\n",
    "\n",
    "non-maximum suppression : IoU가 0.3보다 큰 bounding box를 제거\n",
    "\n",
    "Bounding Box Regression : bounding box의 위치를 조정하는 것"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. R-CNN 모델 전체적인 구조를 보고 R-CNN 모델의 동작을 순서대로 설명해 보세요.\n",
    "\n",
    "1️⃣ Region Proposal: 입력 이미지에 selective search 알고리즘을 적용하여 객체가 있을 만한 RoI(Region of Interest)의 후보 2천 개를 추출합니다.\n",
    "2️⃣ Resize: 추출된 RoI의 후보 2천 개의 크기를 227x227로 변형합니다. (동일한 사이즈로 변형하기 때문에 이미지의 왜곡이 있을 수 있습니다.)\n",
    "3️⃣ 이미 학습된 CNN 구조를 통해서 4,096차원의 특징 벡터를 추출합니다.\n",
    "4️⃣ 각각의 객체별로 학습된 SVM classifier를 이용해서, 추출된 특징 벡터를 분류합니다.\n",
    "5️⃣ Bounding box regression으로 적절한 객체의 경계(bounding box)를 설정합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 객체가 있을만한 후보를 찾는 Region Proposal과 관련된 여러가지 알고리즘이 있습니다. 그중에서 Selective Search 알고리즘 과정에 대해서 설명해 보세요.\n",
    "\n",
    "Selective Search는 색, 무늬 크기, 형태를 바탕으로 주변 픽셀 간의 유사도를 계산합니다. 계산한 유사도를 바탕으로 segmentation을 수행한 후, 작은 segment들을 묶어가며 최종 후보를 찾습니다.\n",
    "\n",
    "Selective Search의 초기 segmentation은 매우 세밀한 영역까지 segmentation 하는 over-segmentation을 하며 유사도가 비슷한 segment들을 반복적으로 묶어갑니다.\n",
    "\n",
    "gpt 답변\n",
    "\n",
    "Selective Search 알고리즘은 주변 픽셀 간의 유사도를 계산하여, 유사도가 높은 픽셀들을 그룹핑합니다. 그룹핑된 픽셀들을 바탕으로 초기에는 아주 세밀한 영역까지 Segmentation을 수행합니다. 그 후, 유사도가 비슷한 Segmentation을 반복적으로 그룹핑합니다. 이렇게 그룹핑된 영역들을 바탕으로 Region Proposal을 수행합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. R-CNN 모델은 Region Proposal이 끝난 후 최종적으로 Classification을 진행합니다. 이 Classification의 진행과정에 대해서 설명해 보세요.\n",
    "\n",
    "RoI를 동일한 사이즈로 맞춘 후, Pre-trained된 Convolutional Neural Network 모델을 통해서 feature extraction(4,096차원)을 수행합니다. 앞의 Feature Extraction 결과 바탕으로 학습한 SVM을 이용해서 feature extraction 결과를 분류합니다.\n",
    "\n",
    "그 후, 2,000개의 proposed region 중에서 IoU 값을 이용해 \"non-maximum suppression\"을 적용해 적합하지 않은 것을 탈락시킵니다. 마지막으로 Bounding box의 위치를 맞추기 위해서 bounding box regression을 실행합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Object Detection과 관련된 개념들\n",
    "\n",
    "##### Sliding window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://miro.medium.com/max/512/1*KCpy3xvBTeX5xTRwB1baCA.gif)\n",
    "\n",
    "sliding window(출처:https://towardsdatascience.com/going-deep-into-object-detection-bed442d92b34)\n",
    "\n",
    "Object Detection은 이미지의 “어느 위치”에 Object가 있는지 알아보는 태스크입니다.\n",
    "\n",
    "Sliding window는 일정 크기의 window를 이미지 위에서 조금씩 옮겨가며 전수조사를 하는 것입니다. Window 사이즈를 바꿔 가면서 Object가 있는 위치를 찾고, 효율적으로 Object 위치를 찾기 위해서 stride를 변경할 수 있습니다. 그러나 계산 비용이 많이 들고 학습 속도가 느리다는 단점이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### IoU (Intersection over Union)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/NoDeu8-1.jpg)\n",
    "https://medium.com/the-research-nest/parking-space-detection-using-deep-learning-9fc99a63875e\n",
    "\n",
    "IoU는 모델이 예측한 bounding box와 실제 정답인 ground truth box가 얼마나 겹치는 지를 측정하는 지표입니다. 만약 100%로 겹치게 되면 IoU 값은 1이 됩니다.\n",
    "\n",
    "Area of Union: predicted bounding box와 ground-truth bounding box를 모두 포함하는 영역\n",
    "Area of Overlap: predicted bounding box와 ground-truth bounding box가 겹치는 부분"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### NMS (Non Maximum/maximal Suppression)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/NoDeu8-2.max-800x600.png)\n",
    "\n",
    "[NMS]\n",
    "https://www.researchgate.net/figure/Non-Maximal-Suppression_fig5_345061606\n",
    "\n",
    "NMS은 수많은 bounding box 중 가장 적합한 box를 선택하는 기법입니다.\n",
    "\n",
    "NMS의 과정\n",
    "\n",
    "1. 모든 bounding box에 대하여 threshold 이하의 confidence score를 가지는 bounding box는 제거합니다.\n",
    "\n",
    "2. 남은 bounding box들을 confidence score 기준으로 내림차순 정렬합니다.\n",
    "\n",
    "3. 정렬 후 가장 confidence score가 높은 bounding box를 기준으로 다른 bounding box와 IoU를 구합니다.\n",
    "\n",
    "4. IoU가 특정 기준 값보다 높으면, confidence score가 낮은 bounding box를 제거합니다.\n",
    "해당 과정을 순차적으로 반복합니다.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### mAP (mean Average Precision)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/NoDeu8-3.png)\n",
    "\n",
    "[Precision-Recall Curve]\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "\n",
    "Precision-Recall Curve: confidence threshold의 변화에 따른 정밀도와 재현율의 변화 곡선입니다.\n",
    "\n",
    "AP: Precision-Recall Curve의 아래 부분 면적을 의미합니다.\n",
    "\n",
    "mAP: AP는 하나의 object에 대한 성능 수치이며, mAP는 여러 object들의 AP를 평균한 값을 의미합니다. 따라서 Object Detection 모델의 성능 평가에 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bounding Box Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/NoDeu8-4.max-800x600.png)\n",
    "\n",
    "[Bounding box regression]\n",
    "https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html\n",
    "\n",
    "Bounding box regression의 목표는 예측 박스($ {P}_x, {P}_y, {P}_w, {P}_h $)와 ground-truth 박스($ {G}_x, {G}_y, {G}_w, {G}_h $)에 가깝게 만드는 것입니다. 더 자세한 내용은 참고 자료를 통해서 확인해 보세요."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img08/13.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 컴퓨터 비전에서 Object detection은 어떤 task 인지 설명해 보세요.\n",
    "\n",
    "Object detection은 한 이미지 안에 여러 개의 객체(multiple objects)가 있을 때, 객체의 경계를 지정(bounding box regression)해주고, 경계 안에 있는 객체의 class가 무엇인지를 분류하는 작업을 동시에 수행하는 것입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
