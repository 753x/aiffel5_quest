{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 딥러닝으로 시작하는 컴퓨터 비전\n",
    "### 5. CNN 하나씩 이해하기 (3) Pooling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5-1. 들어가며"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img05/01.png)\n",
    "![](./img05/02.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 학습 내용\n",
    "\n",
    "Pooling\n",
    " - Pooling의 역할과 장점에 대해서 알아보고 Pooling 종류를 예시로 살펴보며 Pooling 연산 과정을 이해해 봅시다.\n",
    "\n",
    "Convolution + Pooling 종합\n",
    " - Convolution 연산과 Pooling 연산이 합쳐진 CNN 구조를 살펴보며 CNN 구조의 특징에 대해서 알아봅시다.\n",
    "\n",
    "CNN 구조 구현하기\n",
    " - tf.keras 라이브러리를 이용하여 CNN 구조를 직접 코드로 구현해 봅시다.\n",
    "\n",
    "#### 학습 목표\n",
    "Max pooling과 average pooling을 설명할 수 있습니다.\n",
    "\n",
    "Pooling 연산이 convolution 연산에 비해 어떤 강점을 가지고 있는지 설명할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5-2. Pooling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img05/03.png)\n",
    "3차원 이미지 입력 후 conv와 풀링을 번갈아가다가 마지막에 FC를 거쳐서 분류를 하는 구조 (FC는 Fully Connected Layer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img05/04.png)\n",
    "Max Pooling 은 가장 큰 값만 뽑아 내고 나머지는 버리는 방식\n",
    "Average Pooling 은 평균을 뽑아 내는 방식\n",
    "둘다 파라미터를 필요로 하지 않는다.\n",
    "정보를 줄이고 파라미터를 줄여 연산량을 크게 늘이지 않고 다운스케일링이 가능한 방법이 풀링"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img05/05.png)\n",
    "풀링을 통해 다운샘플링. 적절하게 중요한 정보만 뽑아낸다는 의미"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Pooling을 알아보기 전, 이미지 분류를 위한 전형적인 CNN 구조에 대해 다시 한번 설명해 볼까요? 3차원의 Input image가 CNN(Convolution Neural Network) 구조에 들어가면 어떠한 연산을 거치게 되는지 설명해 봅시다.\n",
    "\n",
    "3차원의 Input image가 들어오게 되면 Convolution 연산을 하게 되고 그다음에 오늘 배울 Pooling 연산을 하게 됩니다. 반복해서 Convolution 연산과 Pooling 연산을 하게 되고 어느 순간 FC라고 표현하는 Fully Connected layer를 만나게 됩니다. 마지막으로는 최종적으로 내가 수행하고 싶은 classification을 진행하게 됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Pooling은 어떤 역할을 하고 Pooling을 사용하였을 때 장점에 대해서 설명해 봅시다.\n",
    "\n",
    "Pooling은 Feature map으로 표현된 정보를 축약(down sampling)하는 역할을 하며, Parameter를 사용하지 않고 정보를 압축할 수 있다는 장점이 있습니다. 또한 Pooling은 비선형성을 강화하고, Feature map의 크기를 줄여서 연산 성능을 향상시킬 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 예시로 총 3가지의 Pooling의 종류가 나왔습니다. Max Pooling, Average Pooling, Sum Pooling은 각 Feature map을 어떻게 연산하는지 설명해 봅시다.\n",
    "\n",
    "• Max Pooling: 각 영역에서 가장 큰 값만 뽑아냅니다.\n",
    "• centerdot Average Pooling: 각 영역의 평균값을 사용합니다.\n",
    "• Sum Pooling : 각 영역의 합을 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5-3. Convolution + Pooling 종합"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img05/06.png)\n",
    "패턴을 찾아내는 영역인 Feature Extraction 부분과 분류를 하는 영역인 Classification 부분으로 나누어져 있습니다. Feature Extraction 부분은 Convolution 연산과 Pooling 연산을 반복하며, Classification 부분은 Fully Connected Layer(MLP)로 구성되어 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Convolution Neural Network를 구성하고 있는 가장 핵심적인 연산 Convolution 연산과 Pooling 연산에 대해서 알아보았습니다. 이제 2가지 연산이 다 적용된 CNN은 어떻게 구성되어 있고 어떤 특징을 가지고 있는지 설명해 봅시다\n",
    "\n",
    "CNN은 크게 Feature Extraction과 Classification 영역으로 구성됩니다. 연속적인 CNN 연산(Convolution + Pooling)을 순차적으로 수행하면서 일련의 Feature Map을 생성합니다. CNN 연산을 통해 순차적으로 생성된 Feature map의 크기(높이x너비)는 줄어들지만 채널(깊이)은 증가합니다. 최근에는 더 복잡하고 다양한 Feature 정보를 반영하기 위해, CNN 깊이를 증가시키는 방향으로 점차 발전하고 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5-4. CNN 구조 구현하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "tf.keras 라이브러리를 이용해서 CNN 구조를 구현해봅시다.\n",
    "2D convolutional layer는 tf.keras.layers.Conv2D 객체를 생성하여 구현할 수 있습니다.\n",
    "Conv2D 객체의 자료형은 keras.engine.keras_tensor.KerasTensor입니다.\n",
    "모델을 생성할 때, tf.keras.layers.Input 레이어를 맨 처음에 정의해야 합니다. 여기서는 (28, 28, 1) 크기의 데이터를 입력받는 input layer를 생성했습니다.\n",
    "input_layer.shape 결과에서 처음 보이는 None은 데이터셋의 batch size에 해당됩니다. x라는 레이어 객체는 output 채널이 4개인 convolutional layer이므로 x.shape의 결과는 (None, 28, 28, 4)가 됩니다.\n",
    "\n",
    "중요한 점은, 레이어를 생성할 때 output = Conv2D(params)(input) 형태로 input과 output 변수를 넣고, 이전 레이어의 output을 다음 레이어의 input으로 설정함으로써 레이어들이 서로 연결되도록 해야 한다는 것입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 18:10:41.322373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:10:45.843495Z",
     "start_time": "2023-08-11T09:10:39.213556Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 기본적인 형태의 CNN 모델 구현"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.engine.keras_tensor.KerasTensor'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 4), dtype=tf.float32, name=None), name='conv2d/Relu:0', description=\"created by layer 'conv2d'\")\n"
     ]
    }
   ],
   "source": [
    "# 가로 28, 세로 28, 채널 수 1의 input 데이터를 받는 input layer 생성하기\n",
    "input_layer = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "# 커널의 가로 세로 사이즈는 3이고, 채널 수는 4, zero-padding을 넣고,\n",
    "# stride는 1로 한 Conv2D layer\n",
    "x = tf.keras.layers.Conv2D(filters=4, kernel_size=3, strides=1, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "print(type(x))\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:10:52.509327Z",
     "start_time": "2023-08-11T09:10:52.429770Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 1)\n",
      "(None, 28, 28, 4)\n"
     ]
    }
   ],
   "source": [
    "print(input_layer.shape)\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:11:18.885362Z",
     "start_time": "2023-08-11T09:11:18.880332Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "패딩을 사용했기 때문에 input과 동일한 가로 세로 사이즈를 가지고 있고, 채널 수를 4로 했기 때문에 feature map의 채널 수도 4입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### pooling layer가 포함된 CNN 모델 구현\n",
    "\n",
    "이번에는 pooling layer가 포함된 CNN 모델을 만들어봅시다.\n",
    "(27, 27, 1) 크기의 입력을 받는 input_tensor와 Conv2D 레이어 x1, 그리고 pooling layer에 해당하는 MaxPooling2D 레이어 x2로 구성되어 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Q. 가로 27, 세로 27, 채널 수 1의 input 데이터를 받는 input layer 생성해 보세요.\n",
    "input_tensor = tf.keras.layers.Input(shape=(27, 27, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:12:28.036719Z",
     "start_time": "2023-08-11T09:12:28.031472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Q. 커널의 가로 세로 사이즈는 2이고, 채널 수는 6, zero-padding을 넣고,\n",
    "# stride는 2인 Conv2D layer x1을 생성해 보세요. (활성화 함수 : relu)\n",
    "x1 = tf.keras.layers.Conv2D(filters=6, kernel_size=2, strides=2, padding='same', activation='relu')(input_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:13:04.432115Z",
     "start_time": "2023-08-11T09:13:04.423122Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 6), dtype=tf.float32, name=None), name='conv2d_1/Relu:0', description=\"created by layer 'conv2d_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 6), dtype=tf.float32, name=None), name='max_pooling2d/MaxPool:0', description=\"created by layer 'max_pooling2d'\")\n"
     ]
    }
   ],
   "source": [
    "# 가로 세로 사이즈가 2인 영역에서 최대값을 뽑는 Maxpooling을 적용\n",
    "x2 = tf.keras.layers.MaxPooling2D(2)(x1)\n",
    "print(x1)\n",
    "print(x2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:13:27.823329Z",
     "start_time": "2023-08-11T09:13:27.811823Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "레이어 객체를 쭉 정의한 다음, tf.keras.Model 함수에 input과 output을 연결해서 모델 객체를 생성합니다. model.summary() 함수를 이용하면 완성된 모델의 구조를 한번에 살펴볼 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 7, 7, 5)]         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 4)           184       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 8)           296       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 2, 2, 8)           0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480 (1.88 KB)\n",
      "Trainable params: 480 (1.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(7, 7, 5))\n",
    "convlayer1 = tf.keras.layers.Conv2D(filters=4, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "convlayer2 = tf.keras.layers.Conv2D(filters=8, kernel_size=3, strides=1, padding='valid')(convlayer1)\n",
    "pooling = tf.keras.layers.MaxPooling2D(2)(convlayer2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=pooling)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:14:13.118443Z",
     "start_time": "2023-08-11T09:14:13.087356Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "다음 코드를 실행하면 오류가 발생합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling2d_2\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,16].\n\nCall arguments received by layer \"max_pooling2d_2\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 16), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m convlayer1 \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mConv2D(filters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, strides\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m'\u001B[39m)(input_layer)\n\u001B[1;32m      3\u001B[0m convlayer2 \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mConv2D(filters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, strides\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m'\u001B[39m)(convlayer1)\n\u001B[0;32m----> 4\u001B[0m pooling \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMaxPooling2D\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvlayer2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39minput_layer, outputs\u001B[38;5;241m=\u001B[39mpooling)\n\u001B[1;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1751\u001B[0m, in \u001B[0;36m_create_c_op\u001B[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001B[0m\n\u001B[1;32m   1748\u001B[0m   c_op \u001B[38;5;241m=\u001B[39m pywrap_tf_session\u001B[38;5;241m.\u001B[39mTF_FinishOperation(op_desc)\n\u001B[1;32m   1749\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mInvalidArgumentError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1750\u001B[0m   \u001B[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001B[39;00m\n\u001B[0;32m-> 1751\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(e\u001B[38;5;241m.\u001B[39mmessage)\n\u001B[1;32m   1753\u001B[0m \u001B[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;66;03m# TF_Operation.\u001B[39;00m\n\u001B[1;32m   1755\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extract_traceback:\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer \"max_pooling2d_2\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,16].\n\nCall arguments received by layer \"max_pooling2d_2\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 16), dtype=float32)"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(13, 13, 5))\n",
    "convlayer1 = tf.keras.layers.Conv2D(filters=8, kernel_size=5, strides=2, padding='valid')(input_layer)\n",
    "convlayer2 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=2, padding='valid')(convlayer1)\n",
    "pooling = tf.keras.layers.MaxPooling2D(2)(convlayer2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=pooling)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:20:12.263966Z",
     "start_time": "2023-08-11T09:20:11.294596Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 위의 코드는 왜 오류가 났을까요? 각 Layer로부터의 연산 결과를 손으로 계산하신 것을 근거로 설명해 보세요.\n",
    "\n",
    "두 번째 Conv2D 레이어의 output convlayer2의 크기가 작아서 pooling 연산을 수행할 공간이 부족하기 때문입니다.\n",
    "\n",
    "첫 번째 Conv2D 레이어의 output convlayer1의 크기는 5x5이고, 두 번째 Conv2D 레이어의 output convlayer2의 크기는 1x1입니다. 1x1를 pooling 연산을 하기에는 공간이 부족합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 이미지 분류 CNN 모델"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CNN 모델을 이미지 분류에 사용하려면, Conv2D 레이어의 output인 3차원 feature map에 flatten을 적용한 다음, fully connected layer(Dense)를 연결해야 합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "input_tensor = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# 3차원으로 되어있는 Feature map 결과를 Fully Connected 연결하기 위해서는 Flatten()을 적용해야 합니다.\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "# Flatten 된 결과를 100의 노드를 가진 Fuly Connected Layer와 연결\n",
    "x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax')(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:26:06.037284Z",
     "start_time": "2023-08-11T09:26:05.996815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10816)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               1081700   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1101526 (4.20 MB)\n",
      "Trainable params: 1101526 (4.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Q. tf.keras.Model을 사용하여 model을 정의해 주세요. (위에 코드 참고해서 작성해 보세요.)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T09:26:30.674023Z",
     "start_time": "2023-08-11T09:26:30.660187Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 실습 코드의 맨 아래 코드의 실행 결과로 나온 Total params의 수가 어떻게 나온 값인지, 손으로 계산하고 설명해 보세요.\n",
    "\n",
    "코드에서 각 레이어별 파라미터 개수는 다음과 같이 계산됩니다.\n",
    "\n",
    "1. 첫 번째 Conv2D 레이어\n",
    "필터 개수: 32, 커널 크기: 3x3, 입력 이미지 채널: 1\n",
    "파라미터 개수: (3 * 3 * 1 * 32) + (bias: 32) = 320\n",
    "\n",
    "2. 두 번째 Conv2D 레이어\n",
    "필터 개수: 64, 커널 크기: 3x3, 입력 이미지 채널: 32 (이전 레이어의 필터 개수)\n",
    "파라미터 개수: (3 * 3 * 32 * 64) + (bias: 64) = 18496\n",
    "\n",
    "3. MaxPooling2D 레이어는 파라미터를 가지지 않습니다.\n",
    "\n",
    "4. Flatten 레이어에서 레이어의 파라미터는 없습니다. 이전 레이어에서 출력된 형태를 기반으로 크기를 계산해 봅시다.\n",
    "이전 레이어의 형태는 (13, 13, 64)입니다. 따라서, Flatten 된 결과는 13 * 13 * 64 = 10816 입니다.\n",
    "\n",
    "5. 다섯 번째 Dense 레이어\n",
    "뉴런 개수: 100, 입력 값 개수: 10816 (이전 레이어에서 Flatten 된 결과 크기)\n",
    "파라미터 개수: (10816 * 100) + (bias: 100) = 1081700\n",
    "\n",
    "6. 마지막 Dense 레이어\n",
    "뉴런 개수: 10, 입력 값 개수: 100 (이전 레이어의 뉴런 개수)\n",
    "파라미터 개수: (100 * 10) + (bias: 10) = 1010\n",
    "\n",
    "총 합산하여, Total params의 수는 320 + 18496 + 1081700 + 1010 = 1,101,526 입니다. 따라서 실행 결과로 나온 Total params의 수는 1,101,526으로 계산됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img05/07.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Pooling 연산은 어떤 장점이 있었는지 설명해 보세요.\n",
    "\n",
    "Pooling을 통해 Parameter 연산 없이 Feature map의 차원을 축소할 수 있다는 장점이 있습니다. 차원을 축소 즉, down sampling을 해준다고 표현할 수도 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q.CNN 구조를 크게 2가지로 나눠본다면 어떤 영역들로 구성이 되어 있는지 설명해 보세요. 또한, CNN 구조의 깊이를 증가시키면 어떤 장점이 있는지 설명해 보세요.\n",
    "\n",
    "CNN 구조는 크게 특징을 찾아내는 feature extraction과 실제적으로 이미지 분류를 하는 classification 영역으로 나뉩니다. 또한, CNN 구조의 깊이를 증가시키면 다양하고 복잡한 feature를 찾아낼 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
