{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 딥러닝으로 시작하는 컴퓨터 비전\n",
    "### 1. 컴퓨터 비전 태스크 “상상”해 보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1-1. 노드를 여행하는 히치하이커를 위한 안내서"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "'딥러닝으로 시작하는 컴퓨터 비전'을 모두 학습하면 할 수 있는 것은?\n",
    "프로젝트 1: Image Classification\n",
    "프로젝트 1에서는 VGG16 모델을 사용하여 개와 고양이 사진을 분류해 봅니다. 여러분들은 이 프로젝트에서 VGG16 모델을 직접 구현하고 성능을 확인해 볼 거에요\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/SeuKeuLinSyas_2023-03-30_150258.max-800x600.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델의 정확도는 아래 이미지와 같이 정확도(Accuracy)와 손실(Loss) 그래프를 그려서 확인합니다. 예시로 주어진 코드의 성능이 그리 좋지 않기 때문에 여러분들은 콘텐츠에서 다룬 다양한 방법을 사용하여 모델의 성능을 높여보는 것까지 해보시게 될 거에요."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/SeuKeuLinSyas_2023-03-30_150322.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "프로젝트 2: Object Detection\n",
    "프로젝트 2에서는 오픈 소스로 공개된 모델을 사용하여 Object Detection을 해봅니다. 다양한 모델 중 우리는 Faster RCNN을 사용합니다.\n",
    "\n",
    "여러분들은 이 프로젝트에서 2가지 문제를 해결하셔야 합니다. 첫번째는 LMS에서 제공하는 이미지 외의 다른 이미지를 가져와서 Object Detection을 해보는 것이고, 두번째는 다양한 pre-trained model을 사용하여 결과를 테스트해보는 것입니다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/SeuKeuLinSyas_2023-03-30_150157.max-800x600.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "콘텐츠 구성 및 학습 가이드\n",
    "이번에는 '딥러닝으로 시작하는 컴퓨터 비전'이 어떻게 구성되어 있는지와 어떻게 학습할지를 알아보겠습니다.\n",
    "\n",
    "콘텐츠 구성\n",
    "'딥러닝으로 시작하는 컴퓨터 비전'은 총 10개의 노드로 구성되어 있습니다. 1~9번 노드는 이론이고, 10번 노드는 프로젝트입니다.\n",
    "\n",
    "이론\n",
    "\n",
    "컴퓨터 비전 태스트 '상상'해 보기\n",
    "다층 퍼셉트론(Multi-Layer Perceptron) 구조 복습하기\n",
    "CNN 하나씩 이해하기 (1) 1-Channel Convolution\n",
    "CNN 하나씩 이해하기 (2) 3-Channel Convolution\n",
    "CNN 하나씩 이해하기 (3) Pooling\n",
    "심화된 CNN 구조\n",
    "Transfer Learning 이해하기\n",
    "Object Detection\n",
    "Segmentation\n",
    "프로젝트\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1-2. 들어가며"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/01.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 학습 내용\n",
    "1. 이미지 \"데이터\" 이해하기\n",
    " - 인간이 이미지를 인식하는 방법과 컴퓨터가 이미지를 인식하는 방법을 알아보고, 차이점을 알아봅니다.\n",
    "2. 이미지 내의 정보 찾아보기\n",
    " - 데이터는 정보일까요? 이미지 내의 정보의 특징을 알아봅니다.\n",
    "3. 컴퓨터 비전의 다양한 태스크\n",
    " - 컴퓨터 비전의 대표적인 태스크인 Classification, Object Detection, Segmentation을 알아봅니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 학습목표\n",
    "\n",
    "이미지 데이터가 가진 특징을 이해한다.\n",
    "\n",
    "각 컴퓨터 비전 태스크들의 목표와 차이점을 이해한다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-3. 이미지 \"데이터\" 이해하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/02.png)\n",
    "\n",
    "빛을 제공해주는 태양\n",
    "\n",
    "가시광선 안에는 RGB 세 가지 색상이 있습니다.\n",
    "\n",
    "반사된 빛의 요소 존재(input)\n",
    "\n",
    "반사된 빛이 눈에 들어오고 들어온 빛을 처리하는 세포가 존재함\n",
    "\n",
    "원추세포에는 RGB를 각각 처리하는 영역이 있음\n",
    "\n",
    "인풋으로 들어온 신호가 세포를 통해 전기 신호로 변형되며 이 신호는 뇌를 통해 빨간 사과라고 인식!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/03.png)\n",
    "가로 세로 2차원의 고양이 사진 존재\n",
    "\n",
    "사실은 3차원의 데이터를 가지고 있음(가로 세로 depth)\n",
    "\n",
    "RGB 3개의 채널을 가지고 있음\n",
    "\n",
    "3개의 채널을 통해 입력된 숫자 덩어리는 input으로 컴퓨터에게 전달됨\n",
    "\n",
    "연산장치를 통해 input을 프로세싱하여 고양이 사진을 output으로 출력"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 인간이 이미지를 인식하는 방법과 컴퓨터가 이미지를 인식하는 방법의 차이를 설명해 보세요.\n",
    "\n",
    "인간이 이미지를 인식할 때는 반사된 빛의 일부가 눈에 입력으로 들어오면 눈의 세포를 통해 빛의 신호가 전기 신호로 변환되어 뇌로 전달됩니다. 그 후 뇌에서 이미지가 출력됩니다.\n",
    "\n",
    "반면 컴퓨터는 이미지를 숫자로 인식합니다. 숫자가 입력으로 컴퓨터에 주어지면 컴퓨터의 연산 장치로 연산이 처리되고 결과를 출력합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1-4. 이미지 내의 정보 찾아보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/04.png)\n",
    "\n",
    "숫자덩어리 안에는 의미 정보 패턴을 가지고 있다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/05.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "형태에 초점을 맞춰서 특정 픽셀이 가진 의미를 찾아보자\n",
    "\n",
    "색깔을 통해서 영역을 구분하고 선을 통해서 영역을 나눈것을 합쳐보면 주변과의 관계를 통해 같은 값을 가진것과 아닌것을 확인할 수 있다.\n",
    "\n",
    "![](img01/06.png)\n",
    "\n",
    "관계라는 것은 같다와 다르다로 구분된다.\n",
    "\n",
    "이미지 데이터 속에는 수많은 숫자들이 존재한다. 그 안에는 정보가 담겨 있고 주변 픽셀들과의 관계를 통해 규정된다.\n",
    "\n",
    "이미지 데이터 속 의미를 찾을때는 주변의 여러개 픽셀과 특정 픽셀이 어떤 유사성이 있는지를 반드시 파악해야 한다.\n",
    "\n",
    "그리고 유사성을 비교함으로써 이미지안에 있는 색,형태, 질감을 추론해 낼수 있다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/07.png)\n",
    "\n",
    "이미지는 크게 두가지로 나뉜다. 이미지 안에 하나의 오브젝트(대상 혹은 객체)가 존재하거나 이미지 안에 여러개의 오브젝트가 존재한다.\n",
    "\n",
    "로컬라이제이션은 이미지 안에 존재하는 오브젝트의 위치를 찾는 것이다.(바운딩박스 혹은 B Box는 오브젝트의 위치를 표현하는 방법이다.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/08.png)\n",
    "\n",
    "오브젝트 디텍션은 바운딩 박스 여러개를 만들고 이것이 무엇인지 지정해주는 작업을 했다.\n",
    "\n",
    "바운딩 박스는 위치를 해주고 그것이 무엇인지 답을 달아 분류를 해주는 역할\n",
    "\n",
    "오른쪽 그림은 사람과 연을 구분해준다. 사람이라면 사람일 확률이 몇%인지도 알려준다.\n",
    "(B Box(localization) + Classification = Object Detection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img01/09.png)\n",
    "\n",
    "분할\n",
    "\n",
    "왼쪽 상단 : B Box를 만들어 Localize를 해준다. B Box안에 양을 알려줌(Classification)\n",
    "여러마리의 양이 있지만 하나로 묶어서 양이라고만 표현하기 때문에 Object Detection이라고 할 수 없다.\n",
    "\n",
    "오른쪽 상단 : B Box를 만들어 Localize를 해준다. 양이 몇마리인지까지 알려주기 때문에 Object Detection이라고 할 수 있다.\n",
    "\n",
    "왼쪽 하단 : 이미지를 픽셀단위로 쪼개 픽셀의 class가 무엇인지를 표기\n",
    "\n",
    "오른쪽 하단 : 왼쪽과 비슷하지만 조금더 발전된 방향이다. 왼쪽은 양을 하나로 묶었지만 오른쪽은 양의 개별 객체(개체, instance)를 구분했다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 컴퓨터 비전의 각 태스크는 어떻게 구분할 수 있나요?\n",
    "\n",
    "컴퓨터 비전의 태스크는 Single Object인지 Multiple Object인지에 따라 구분할 수 있습니다. Single Object를 다루는 태스크에는 Classification과 Localization이 있고, Multiple Object를 다루는 태스크는 Object Detection과 Instance Segmentation이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Classification과 Localization를 설명해 보세요.\n",
    "\n",
    "Classification: 1개의 object의 class를 예측하는 태스크입니다. Localization: object의 위치를 찾아내는 태스크로, Bounding Box를 통해 위치를 지정합니다.\n",
    "\n",
    "GPT 답변\n",
    "Classification과 Localization은 컴퓨터 비전에서 매우 중요한 개념입니다. 이 둘은 객체 검출(Object Detection) 문제를 해결하는 데 기반이 되는 기술입니다.\n",
    "\n",
    "Classification은 객체가 무엇인지를 분류하는 작업입니다. 이 작업은 이미지 내의 객체를 인식하고 해당 객체가 어떤 클래스에 해당하는지 (예: 고양이, 개, 자동차 등) 파악하는 것입니다. 일반적으로 딥러닝 모델은 이미지를 입력으로 받아들이고 객체를 인식하고, 해당 객체를 대표하는 클래스를 예측하는 출력을 생성합니다.\n",
    "\n",
    "반면, Localization은 객체의 위치를 찾는 작업입니다. 이 작업은 이미지에서 객체가 어디에 위치하는지를 파악하는 것입니다. 대개 딥러닝 모델은 이미지에서 객체 위치에 대한 정보 (bounding box)를 출력합니다. 또한 Localization을 통해 모델이 인식한 객체가 이미지에서 어디에 위치하는지를 시각화할 수 있습니다.\n",
    "\n",
    "따라서, Classification은 객체가 무엇인지를 파악하는 작업에 중점을 둔 반면, Localization은 객체의 위치에 대한 정보를 기반으로 객체를 검출하는 작업에 중점을 둡니다. 보통 객체 검출 문제를 해결하기 위해서는 Classification과 Localization을 모두 고려해야 합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Object Detection을 설명해 보세요.\n",
    "\n",
    "Object Detection는 Bounding Box로 위치를 지정하고, 각 Bounding Box 안의 obejct를 classification을 하는 것입니다. Object Detection = Bounding Box Regression (Localization) + Multi-Labeled Classification\n",
    "\n",
    "GPT 답변\n",
    "Object Detection은 컴퓨터 비전 분야에서 객체를 검출하는 기술 중 하나로, 이미지나 비디오에서 객체의 위치와 클래스를 판별하는 작업을 말합니다.\n",
    "\n",
    "Object Detection의 목적은 이미지나 비디오에서 여러 객체를 자동으로 검출하고, 각 객체의 위치와 클래스를 정확하게 파악하는 것입니다. 이를 위해서는 다음과 같은 절차를 거칩니다.\n",
    "\n",
    "1. 이미지나 비디오 데이터를 입력으로 받습니다.\n",
    "2. 객체 검출 알고리즘을 사용하여 이미지 내의 객체들을 감지합니다.\n",
    "3. 객체가 검출되면, 그 객체의 위치와 클래스를 결정합니다.\n",
    "4. 검출된 객체들을 Bounding Box로 표시하고, 해당 객체의 클래스 이름을 함께 표시합니다.\n",
    "\n",
    "이를 위해 딥러닝을 이용한 Object Detection 기법이 가장 일반적입니다. 대표적인 딥 러닝 기반 객체 검출 알고리즘으로는 RCNN 계열 (RCNN, Fast-RCNN, Faster-RCNN), YOLO 계열 (You Only Look Once, YOLOv2, YOLOv3), SSD (Single Shot MultiBox Detector) 등이 있습니다.\n",
    "\n",
    "Object Detection은 자율 주행을 비롯한 다양한 분야에서 활용됩니다. 자율 주행 자동차에서는 카메라를 이용하여 도로 상황을 인식하고, 보행자나 차량 등의 객체를 검출하여 이에 대한 조치를 취합니다. 또한, 보안, 검색 등의 분야에서도 활용됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Segmentation을 설명해 보세요.\n",
    "\n",
    "Segmentation은 픽셀 수준에서의 의미를 찾는 태스크입니다. Segmentation은 이미지를 픽셀 단위로 분해하고 픽셀의 class를 분류하는 Semantic Segmentation와 픽셀이 어떤 개별 객체(개체, Instance)로 구분되는지 분류하는 Instance Segmentation로 구분할 수 있습니다.\n",
    "\n",
    "GPT 답변\n",
    "Segmentation은 컴퓨터 비전에서 이미지를 픽셀 수준에서 분할하는 기술입니다. 이를 통해 이미지를 보다 정확하고 세부적으로 분석할 수 있습니다.\n",
    "\n",
    "Segmentation은 크게 두 가지 유형으로 나뉩니다.\n",
    "\n",
    "1. Semantic Segmentation\n",
    "Semantic Segmentation은 이미지를 픽셀 수준에서 분할 하며, 동일한 클래스에 속한 영역을 동일한 색으로 표시합니다. 예를 들어, 고양이나 개 같은 동물들은 분할된 영역 내에서 모두 같은 색으로 표시됩니다.\n",
    "\n",
    "2. Instance Segmentation\n",
    "Instance Segmentation은 이미지를 픽셀 수준에서 분할 하며, 각 객체 인스턴스에 고유한 식별자를 지정합니다. 이를 통해 이미지 내 여러 객체인스턴스를 식별하고, 각 객체를 개별적으로 분석할 수 있습니다.\n",
    "\n",
    "이를 위해 딥러닝 모델 중에서는 주로 Fully Convolutional Network (FCN), U-Net, Mask R-CNN 등이 사용됩니다.\n",
    "\n",
    "Segmentation은 대표적으로 의료 영상 분석, 자율주행, 이미지 보강 및 합성 등의 분야에서 적용됩니다. 예를 들어 의료 영상에서는 세포, 조직, 기관 등을 분할해내어 질환이나 암 등을 정확하게 진단하기 위해 사용되고, 자율주행 분야에서는 카메라로 인식한 도로 영역을 분할하여 차선, 보행자, 차량 등을 정확하게 분리하고 인식하여 안전한 주행을 할 수 있도록 돕습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./img01/10.png)\n",
    "\n",
    "관계는 유사성, 같다/다르다로 구분"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 종합 퀴즈"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 이미지 데이터를 분석한다는 의미는 무엇인가요?\n",
    "\n",
    "이미지 데이터를 분석한다는 의미는 3차원의 숫자 덩어리를 입력으로 받아 그 안에 숨겨진 패턴을 찾는다는 뜻입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 이미지의 픽셀이 가진 의미는 무엇에 의해 결정되나요?\n",
    "\n",
    "이미지의 픽셀의 의미는 주변 픽셀 간의 유사성(같다 또는 다르다)에 의해 결정됩니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
